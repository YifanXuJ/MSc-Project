{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Provider for CNN in Supervised Learning Phase\n",
    "\n",
    "Aim: assign 16/32/64/128 clusters to 4 true classes: pore, gypsum, celestite, bassanite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, this is for experimenting vgg16 with round seg res and then rec res. Beeter file formatting can be found in specific jupytor notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 (k-fold?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D #images are two dimensional. Videos are three dimension.\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target segmentation results \n",
    "res_folder = 'large_clusters_rec'\n",
    "seg_model = 'k-means'   # choose between 'gmm' and 'k-means'\n",
    "seg_nd = '3d'   # choose between '3d' and '4d'\n",
    "cluster_num = 16   # choose between 16, 32, 64, and 128\n",
    "\n",
    "# Data path\n",
    "base_folder = os.path.join(os.getcwd(), res_folder, seg_model, seg_nd, 'cluster_{}'.format(cluster_num))\n",
    "\n",
    "# corresponding label csv file\n",
    "csv_file = os.path.join(os.getcwd(), '{}_{}_{}_f1.csv'.format(seg_model, seg_nd, cluster_num))\n",
    "\n",
    "# read csv file\n",
    "df = pd.read_csv(csv_file, usecols = ['slice', 'current_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_num_str(c):\n",
    "    c = str(c).zfill(3)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filename as new column\n",
    "\n",
    "df['filename'] = df['slice'].map(str) + '\\VA10_0050_0' + df['slice'].map(str) + '_' + df['current_cluster'].map(get_cluster_num_str)  + '.rec.8bit.png'\n",
    "df['predict_class'] = df['predict_class'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly get 200 slices from [400, 800] and them select all clusters for these slices to form a balanced training set\n",
    "slice_list = np.array(range(400, 801)) # [400,800] inclusive, 401 in total\n",
    "train_slice, other_set = train_test_split(slice_list, test_size=0.5, random_state=104)\n",
    "val_slice, test_slice = train_test_split(other_set, test_size=0.5, random_state=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df.loc[df['slice'].isin(train_slice)]\n",
    "val_set = df.loc[df['slice'].isin(val_slice)]\n",
    "test_set = df.loc[df['slice'].isin(test_slice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice</th>\n",
       "      <th>current_cluster</th>\n",
       "      <th>predict_class</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>400\\VA10_0050_0400_000.rec.8bit.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>400\\VA10_0050_0400_001.rec.8bit.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>400\\VA10_0050_0400_002.rec.8bit.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>400\\VA10_0050_0400_003.rec.8bit.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>400\\VA10_0050_0400_004.rec.8bit.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slice  current_cluster predict_class                             filename\n",
       "0    400                0             1  400\\VA10_0050_0400_000.rec.8bit.png\n",
       "1    400                1             1  400\\VA10_0050_0400_001.rec.8bit.png\n",
       "2    400                2             3  400\\VA10_0050_0400_002.rec.8bit.png\n",
       "3    400                3             1  400\\VA10_0050_0400_003.rec.8bit.png\n",
       "4    400                4             1  400\\VA10_0050_0400_004.rec.8bit.png"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the segmentation result to leave only the ROI (700, 855) [DO NOT RUN BEFORE CHECKING THE CURRENT SIZE OF TARGETS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target segmentation results \n",
    "res_folder = 'large_clusters_rec'\n",
    "seg_model = 'gmm'   # choose between 'gmm' and 'k-means'\n",
    "seg_nd = '4d'   # choose between '3d' and '4d'\n",
    "cluster_num = 128   # choose between 16, 32, 64, and 128\n",
    "\n",
    "# Data path\n",
    "base_folder = os.path.join(os.getcwd(), res_folder, seg_model, seg_nd, 'cluster_{}'.format(cluster_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MSc-Project\\\\large_clusters_rec\\\\gmm\\\\4d\\\\cluster_128'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "imgs = glob.glob(os.path.join(base_folder, '*', '*.png'))\n",
    "for i in imgs:\n",
    "    crop = cv2.imread(i)[353:1053, 282:1137]\n",
    "    cv2.imwrite(i, crop)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-means 3d 16: 2m 4.2s\n",
    "k-means 4d 16: 2m 2.9s\n",
    "k-means 3d 32: 4m 2.3s\n",
    "k-means 4d 32: 4m 5.6s\n",
    "k-means 3d 64: 7m 53.6s\n",
    "k-means 4d 64: 7m 54.9s\n",
    "k-means 3d 128: 15m 40.2s\n",
    "k-means 4d 128: 15m 37.6s\n",
    "gmm 3d 16: 1m 59.2s\n",
    "gmm 4d 16: 2m 2.5s\n",
    "gmm 3d 32: 3m 50.0s\n",
    "gmm 4d 32: 3m 47.9s\n",
    "gmm 3d 64: 7m 31.4s\n",
    "gmm 4d 64: 7m 35.2s\n",
    "gmm 3d 128: 14m 50.3s\n",
    "gmm 4d 128: 14m 51.1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 validated image filenames belonging to 4 classes.\n",
      "Found 1600 validated image filenames belonging to 4 classes.\n",
      "Found 1616 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_set, directory=base_folder,\n",
    "                                             x_col='filename',\n",
    "                                             y_col='predict_class',\n",
    "                                             target_size=(700, 855),\n",
    "                                             batch_size=16,\n",
    "                                             shuffle=True,\n",
    "                                             class_mode='categorical',\n",
    "                                             seed=7)\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=val_set, directory=base_folder,\n",
    "                                             x_col='filename',\n",
    "                                             y_col='predict_class',\n",
    "                                             target_size=(700, 855),\n",
    "                                             batch_size=16,\n",
    "                                             shuffle=True,\n",
    "                                             class_mode='categorical',\n",
    "                                             seed=7)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_set, directory=base_folder,\n",
    "                                             x_col='filename',\n",
    "                                             y_col=None,\n",
    "                                             target_size=(700, 855),\n",
    "                                             batch_size=16,\n",
    "                                             shuffle=False,\n",
    "                                             class_mode=None,\n",
    "                                             seed=7\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with VGG16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda create --name base-tf --clone tf-gpu-nvcc\n",
    "\n",
    "tf-gpu-nvcc is the one used for all previous development but had conflicts for version of h5py in conda and pip. Did not find out the solution is to uninstall the version in pip, not uninstall from conda. because jupyter is always trying to refer to packages in conda. Also tried to roll-back to previous version of conda env by conda install --revision & conda install --rev 2, but nothing seemed to happen.\n",
    "\n",
    "base-tf is a clone version of tf-gpu-nvcc before revision was done.\n",
    "\n",
    "test-uninstall is a clone version of tf-gpu-nvcc after revision. Found the reason of DLL error was because of version conflicts in conda and pip. Solution is to delete either conda's h5py or pip's h5py. 'cannot find File attribute'  is due to jupyter trying to use the packages inside conda env. Solution is to uninstall pip one rather than conda one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16(include_top=False, input_shape=(700, 855, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 700, 855, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 700, 855, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 700, 855, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 350, 427, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 350, 427, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 350, 427, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 175, 213, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 175, 213, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 175, 213, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 175, 213, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 87, 106, 256)      0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 87, 106, 512)      1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 87, 106, 512)      2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 87, 106, 512)      2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 43, 53, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 43, 53, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 43, 53, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 43, 53, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 21, 26, 512)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 279552)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 1118212   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,832,900\n",
      "Trainable params: 1,118,212\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Flatten()(vgg16_model.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "model = Model(inputs=vgg16_model.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s1923493\\AppData\\Local\\Temp\\ipykernel_10176\\2398137845.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_history = model.fit_generator(generator=train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "200/200 [==============================] - 97s 448ms/step - loss: 0.3341 - accuracy: 0.9400 - val_loss: 0.1874 - val_accuracy: 0.9650\n",
      "Epoch 2/7\n",
      "200/200 [==============================] - 90s 447ms/step - loss: 0.0866 - accuracy: 0.9809 - val_loss: 0.1152 - val_accuracy: 0.9787\n",
      "Epoch 3/7\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.1101 - val_accuracy: 0.9844\n",
      "Epoch 4/7\n",
      "200/200 [==============================] - 89s 446ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.1291 - val_accuracy: 0.9844\n",
      "Epoch 5/7\n",
      "200/200 [==============================] - 90s 447ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1171 - val_accuracy: 0.9819\n",
      "Epoch 6/7\n",
      "200/200 [==============================] - 89s 447ms/step - loss: 0.0279 - accuracy: 0.9937 - val_loss: 0.1731 - val_accuracy: 0.9819\n",
      "Epoch 7/7\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1553 - val_accuracy: 0.9869\n",
      "Training time:  0:10:35.132742\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('vgg16.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "model_history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=7,\n",
    "                    callbacks=callbacks, verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s1923493\\AppData\\Local\\Temp\\ipykernel_10176\\1041194762.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred=model.predict_generator(test_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 36s 353ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                             steps=STEP_SIZE_TEST,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.0000000e+00, 8.7173673e-38, 5.8059596e-14],\n",
       "       [1.7404351e-36, 1.0000000e+00, 0.0000000e+00, 1.5984313e-19],\n",
       "       [1.2185826e-02, 4.3380901e-14, 1.2810710e-21, 9.8781419e-01],\n",
       "       ...,\n",
       "       [8.4862138e-30, 4.5451602e-26, 0.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 3.5413367e-21, 0.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 4.1316549e-23]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s1923493\\AppData\\Local\\Temp\\ipykernel_10176\\608566942.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set['res'] = pd.Series(predicted_class_indices)\n"
     ]
    }
   ],
   "source": [
    "# test_set['res'] = pd.Series(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_set.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = pd.Series(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9876237623762376\n"
     ]
    }
   ],
   "source": [
    "correct = test_df[test_df['predict_class'] == test_df['label'].map(str)].shape[0]\n",
    "print(\"Test Accuracy: \", correct/len(predicted_class_indices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to alter data structure of the folder of segmentation results to use flow_from_dirctory, but then figure out there's a function called flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories following the requiremnets of flow_from_dict and ImageDataGenerator(...).flow()\n",
    "train_dir = os.path.join(os.getcwd(), 'test_dst')\n",
    "os.makedirs(train_dir)\n",
    "\n",
    "for i in range(4):\n",
    "    os.makedirs(os.path.join(train_dir, str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\400\\\\VA10_0050_0400_000.rec.8bit.png',\n",
       " 'd:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\400\\\\VA10_0050_0400_001.rec.8bit.png',\n",
       " 'd:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\400\\\\VA10_0050_0400_002.rec.8bit.png',\n",
       " 'd:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\400\\\\VA10_0050_0400_003.rec.8bit.png',\n",
       " 'd:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\753\\\\VA10_0050_0753_000.rec.8bit.png',\n",
       " 'd:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\753\\\\VA10_0050_0753_001.rec.8bit.png',\n",
       " 'd:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\753\\\\VA10_0050_0753_002.rec.8bit.png',\n",
       " 'd:\\\\MSc-Project\\\\test_src\\\\gmm\\\\3d\\\\cluster_16\\\\753\\\\VA10_0050_0753_003.rec.8bit.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_files = glob.glob(os.path.join(os.getcwd(), 'large_clusters_rec', 'gmm', '3d', 'cluster_16', '*', '*.png'))\n",
    "all_files = glob.glob(os.path.join(os.getcwd(), 'test_src', 'gmm', '3d', 'cluster_16', '*', '*.png'))\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.loc[df['slice'].isin(slice_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.path.join(os.getcwd(), 'test_src', 'gmm', '3d', 'cluster_16')\n",
    "dst_path = os.path.join(os.getcwd(), 'test_dst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test_df.itertuples(index=False):\n",
    "    src_p = os.path.join(src_path, str(row.slice), row.filename)\n",
    "    img = cv2.imread(src_p)[353:1053, 282:1137]\n",
    "    dst_p = os.path.join(dst_path, str(row.predict_class), row.filename)\n",
    "    cv2.imwrite(dst_p, img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some notes and todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced dataset again\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the threshold and use the labeling to evaluate the performance as a whole --> test labeling\n",
    "# use the finalized labeling for cnns\n",
    "# visualise csv files to get more findings\n",
    "# Using CNN at this stage, could also help find features. especially the transfering learning, we can freeze layers to utilize in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the above tasks, try to first build up the pipeline for combining different clusters and evaluate. --> basic functions has already been established bi visual_plots file. Can use do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\MSc-Project\\\\cnn_data_loader.ipynb',\n",
       " 'd:\\\\MSc-Project\\\\testing_func.ipynb',\n",
       " 'd:\\\\MSc-Project\\\\test_keras_fun.ipynb',\n",
       " 'd:\\\\MSc-Project\\\\unsupervised_evaluation.ipynb',\n",
       " 'd:\\\\MSc-Project\\\\volume_analysis.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = os.getcwd()\n",
    "l = glob.glob(os.path.join(p, '*.ipynb'))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\MSc-Project\\\\vgg16.h5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = os.getcwd()\n",
    "l = glob.glob(os.path.join(p, '*.h5'))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-nvcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
